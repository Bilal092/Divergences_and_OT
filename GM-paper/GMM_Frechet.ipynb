{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "primary-uncertainty",
   "metadata": {},
   "source": [
    "# Fitting Gaussian Mixture on a data sample using features from a pre-trained Model\n",
    "\n",
    "Consider the set of all $K$-dimensional categorical distributions given by\n",
    "\n",
    "\\begin{equation}\n",
    "    \\mathcal{C} = \\bigg\\{ \\mathbf{c} \\in \\mathbb{R}^{K}_{+} :  \\mathbf{c} \\geq 0,\\ \\mathbf{c}^{\\rm T}\\mathbf{1} = 1 \\bigg\\} \\subset \\mathbb{R}^{K}_{+}.\n",
    "\\end{equation}\n",
    "\n",
    "In this code we consider the set of gaussian mixtures for the set of distributions $\\{ \\nu_{i} \\}_{i = 1}^{K} $ given by given by:\n",
    "\\begin{equation}\n",
    "\t\t\\mathcal{GM} \\bigg(\\mathbf{c}, \\{ \\nu_{i} \\}_{i = 1}^{K} \\bigg) = \\bigg\\{ \\sum_{i = 1}^{K} c_{i} \\nu_{i}, \\ \\forall \\mathbf{c} \\in \\mathcal{C} \\bigg\\}\n",
    "\t\\end{equation}\n",
    "For the mixture of gaussian distributions $\\{ \\nu_{i} \\}_{i = 1}^{K} $ with means $\\{ \\mu_{i} \\}_{i = 1}^{K} $ and covariance matrices $\\{ \\Sigma_{i} \\}_{i = 1}^{K} $, mixture means and covariance are\n",
    "\n",
    "\n",
    "\\begin{gather*}\n",
    " \\bar{\\mu}_{\\mathbf{c}} = \\sum_{k =1}^{K} c_{k} \\mu_{k}\\  \\text{,  }\n",
    " \\,\\,\\,\\, \\Sigma_{\\mathbf{c}} = \\sum_{k =1}^{K} c_k \\big( \\Sigma_k + \\mu_{k} \\mu_{k}^{\\top} - \\bar{\\mu}_{\\mathbf{c}} \\bar{\\mu}_{\\mathbf{c}}^\\top \\big)\n",
    "\\end{gather*}\n",
    "\n",
    "For a data sample $\\nu_{*}$, we employed Frank-Wolfe Based optimization routine to find the best matching mean, covaraince pair from the the set of all possible mixtures of $\\{ \\nu_{i} \\}_{i = 1}^{K} $ to fit with mean  and covaraince of $\\nu_{*}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "renewable-spice",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy.optimize import check_grad\n",
    "from scipy.optimize import approx_fprime\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "#%%\n",
    "'''\n",
    "    mx: mean of source with size: n x 1\n",
    "    M: means of target distributions with size: n x K, where K indicates number of data-classes.\n",
    "    covx: covariance matrix of source with size: n x 1\n",
    "    covM: array of covariance matrices of target distributions with size: K x n x n, where K indicates number of data-classes.\n",
    "    max_iter: max_iterations of Frank Wolfe\n",
    "    tol: tolerance for gradient check\n",
    "    divg: divergences to be used for computations\n",
    "    max_iter: maximum of frank wolfe iterations\n",
    "    min_tol: minimum tolerance for gardient checking\n",
    "    print_iter: priniting values of maixture weights for each iteration\n",
    "'''\n",
    "class GM_FW:\n",
    "    def __init__(self, mux, M, covx, covM, c0,  max_iter = None, min_tol = None, print_iter = None):\n",
    "        # instance attributes which should be initilzied with class\n",
    "        self.mux = mux\n",
    "        self.M = M\n",
    "        self.covx = covx\n",
    "        self.covM = covM\n",
    "        self.c0 = c0\n",
    "\n",
    "        \n",
    "        self.sqrt_covx = sp.linalg.sqrtm(covx)\n",
    "        self.I = np.identity(np.size(mux))\n",
    "\n",
    "        # attributes to be keep track of computations\n",
    "        self.c = np.zeros_like(c0)\n",
    "        self.mubar = np.zeros_like(mux)\n",
    "        self.hat_covM = self.covM + self.M.T.reshape([self.M.shape[1], self.M.shape[0], 1]) @ self.M.T.reshape([M.shape[1], 1, M.shape[0]])\n",
    "        self.tilde_covM = np.zeros_like(covM)\n",
    "        self.tilde_sigma_c = np.zeros([covM.shape[1], covM.shape[2]])\n",
    "        self.zeta_c = np.zeros([covM.shape[1], covM.shape[2]])\n",
    "        \n",
    "        if max_iter == None:\n",
    "            self.max_iter = 1000\n",
    "        else:\n",
    "            self.max_iter = max_iter\n",
    "\n",
    "        if min_tol == None:\n",
    "            self.min_tol = 1e-6\n",
    "        else:\n",
    "            self.min_tol = min_tol\n",
    "        \n",
    "        if print_iter == None:\n",
    "            self.print_iter = False\n",
    "        elif print_iter == False:\n",
    "            self.print_iter = False\n",
    "        elif print_iter == True:\n",
    "            self.print_iter = True\n",
    "        else:\n",
    "            self.print_iter = False\n",
    "\n",
    "        self.obj_vals = np.zeros([self.max_iter])\n",
    "        self.grads = np.zeros([self.max_iter, np.size(self.c)])\n",
    "        self.weights = np.zeros([self.max_iter, np.size(self.c)])\n",
    "    \n",
    "    def reset_values(self):\n",
    "        # self.mux = mux\n",
    "        # self.M = M\n",
    "        # self.covx = covx\n",
    "        # self.covM = covM\n",
    "        # self.c0 = c0\n",
    "        # self.divg = divg\n",
    "\n",
    "        self.sqrt_covx = sp.linalg.sqrtm(self.covx)\n",
    "        self.I = np.identity(np.size(self.mux))\n",
    "\n",
    "        # attributes to be keep track of computations\n",
    "        self.c = np.zeros_like(self.c0)\n",
    "        self.mubar = np.zeros_like(self.mux)\n",
    "        self.hat_covM = self.covM + \\\n",
    "            self.M.T.reshape([self.M.shape[1], self.M.shape[0], 1]\n",
    "                         ) @ self.M.T.reshape([self.M.shape[1], 1, self.M.shape[0]])\n",
    "        self.tilde_covM = np.zeros_like(self.covM)\n",
    "        self.tilde_sigma_c = np.zeros([self.covM.shape[1], self.covM.shape[2]])\n",
    "        self.zeta_c = np.zeros([self.covM.shape[1], self.covM.shape[2]])\n",
    "\n",
    "        # if max_iter == None:\n",
    "        #     self.max_iter = 1000\n",
    "        # else:\n",
    "        #     self.max_iter = max_iter\n",
    "\n",
    "        # if min_tol == None:\n",
    "        #     self.min_tol = 1e-6\n",
    "        # else:\n",
    "        #     self.min_tol = min_tol\n",
    "\n",
    "        # if print_iter == None:\n",
    "        #     self.print_iter = False\n",
    "        # elif print_iter == False:\n",
    "        #     self.print_iter = False\n",
    "        # elif print_iter == True:\n",
    "        #     self.print_iter = True\n",
    "        # else:\n",
    "        #     self.print_iter = False\n",
    "\n",
    "        self.obj_vals = np.zeros([self.max_iter])\n",
    "        self.grads = np.zeros([self.max_iter, np.size(self.c)])\n",
    "        self.weights = np.zeros([self.max_iter, np.size(self.c)])\n",
    "\n",
    "    def initialize_weights(self):\n",
    "        self.c = self.c0\n",
    "\n",
    "    def update_mubar(self):\n",
    "        self.mubar =  np.sum(self.c[np.newaxis,:] * self.M, axis = 1, keepdims = True)\n",
    "    \n",
    "    def compute_mmd(self):\n",
    "        return np.linalg.norm(self.mux - self.M@self.c)**2\n",
    "    \n",
    "    def compute_mmd_grad(self):\n",
    "        return 2*self.M.T @ (self.M @ self.c[:,np.newaxis] - self.mux)\n",
    "\n",
    "    def update_tilde_covM(self):\n",
    "        self.tilde_covM = self.hat_covM - (self.mubar@self.mubar.T)[np.newaxis,:,:]\n",
    "\n",
    "        \n",
    "    def update_tilde_sigma_c(self):\n",
    "        self.tilde_sigma_c = np.sum(\n",
    "            self.c[:, np.newaxis, np.newaxis] * self.tilde_covM, axis=0)\n",
    "            \n",
    "    def update_zeta_c(self):\n",
    "        temp = sp.linalg.sqrtm(self.sqrt_covx @ self.tilde_sigma_c @ self.sqrt_covx)\n",
    "        self.zeta_c = (temp + temp.T)/2\n",
    "\n",
    "    def compute_bures(self):\n",
    "        temp =  np.trace( self.covx + self.tilde_sigma_c - 2 * self.zeta_c )\n",
    "        return temp\n",
    "    \n",
    "    def compute_bures_grad_tilde_sigma_c(self):\n",
    "        return self.I - self.sqrt_covx @ sp.linalg.pinv(self.zeta_c) @ self.sqrt_covx\n",
    "    \n",
    "    def compute_bures_grad_c(self):\n",
    "        G = self.compute_bures_grad_tilde_sigma_c()\n",
    "        rho = (self.M.T.reshape(self.M.shape[1], self.M.shape[0],1) @ self.mubar.T) + self.mubar @ self.M.T.reshape(self.M.shape[1],1,self. M.shape[0])\n",
    "        temp = np.sum(G[np.newaxis, :, :] * (self.hat_covM - rho ), axis=(1, 2))[:, np.newaxis]\n",
    "        return temp\n",
    "    \n",
    "    def compute_frechet(self):\n",
    "        B = self.compute_bures()\n",
    "        mmd = self.compute_mmd()\n",
    "        return B + mmd\n",
    "\n",
    "    def compute_frechet_grad(self):\n",
    "        GB = self.compute_bures_grad_c()\n",
    "        Gmmd = self.compute_mmd_grad()\n",
    "        return GB + Gmmd\n",
    "\n",
    "\n",
    "    def FW_frechet_routine(self):\n",
    "        self.initialize_weights()\n",
    "        for i in range(0, self.max_iter):\n",
    "            self.update_mubar()\n",
    "            self.update_tilde_covM()\n",
    "            self.update_tilde_sigma_c()\n",
    "            self.update_zeta_c()\n",
    "            self.compute_bures_grad_c()\n",
    "            self.obj_vals[i] = self.compute_frechet()\n",
    "            g = self.compute_frechet_grad()\n",
    "            #print(g)\n",
    "            self.grads[i, :] = np.squeeze(g)\n",
    "            s = np.zeros_like(self.c)\n",
    "            idx = np.argmin(g)\n",
    "            s[idx] = 1\n",
    "            gamma = 2 / (2 + i)\n",
    "            self.c = (1 - gamma) * self.c + gamma * s\n",
    "            \n",
    "            self.weights[i, :] = self.c\n",
    "            if self.print_iter == True:\n",
    "                print(\"iter = i\")\n",
    "                print(self.c)\n",
    "    \n",
    "    def FW_bures_routine(self):\n",
    "\n",
    "        # commented part must be uncommented for gradient-checking\n",
    "        \n",
    "        # def bures_grad_num(c_i, epsilon):\n",
    "            \n",
    "        #     num_grad = np.zeros_like(c_i)\n",
    "        #     I = np.identity(c_i.size)\n",
    "        #     for i in range(0, num_grad.size):\n",
    "        #         num_grad[i] = (bures(c_i + epsilon * I[:,i]) - bures(c_i) ) / epsilon\n",
    "            \n",
    "        #     return num_grad\n",
    "            \n",
    "\n",
    "        # def bures(c_i):\n",
    "            \n",
    "        #     mubar =  np.sum(c_i[np.newaxis,:] * self.M, axis = 1, keepdims = True)\n",
    "        #     # k, n, n - n,n => k,n,n\n",
    "        #     tilde_covM = self.hat_covM \n",
    "        #     #k,.,. * k,n,n => n,n\n",
    "        #     tilde_sigma_c = np.sum(c_i[:, np.newaxis, np.newaxis] * tilde_covM, axis=0) - mubar@mubar.T\n",
    "\n",
    "        #     #n,n\n",
    "        #     zeta_ci = sp.linalg.sqrtm(self.sqrt_covx @ tilde_sigma_c @ self.sqrt_covx)\n",
    "\n",
    "        #     #n,n\n",
    "        #     zeta_ci = (zeta_ci + zeta_ci.T)/2\n",
    "\n",
    "        #     #scalar\n",
    "        #     temp =  np.trace( tilde_sigma_c + self.covx  - 2 * zeta_ci )\n",
    "        #     return temp\n",
    "        \n",
    "        # def bures_grad(c_i):\n",
    "\n",
    "        #     mubar =  np.sum(c_i[np.newaxis,:] * self.M, axis = 1, keepdims = True)\n",
    "\n",
    "        #     tilde_covM = self.hat_covM - (mubar@mubar.T)[np.newaxis,:,:]\n",
    "\n",
    "        #     tilde_sigma_c = np.sum(c_i[:, np.newaxis, np.newaxis] * tilde_covM, axis=0)\n",
    "\n",
    "        #     zeta_ci = sp.linalg.sqrtm(self.sqrt_covx @ tilde_sigma_c @ self.sqrt_covx)\n",
    "        #     zeta_ci = (zeta_ci + zeta_ci.T)/2\n",
    "\n",
    "        #     G = self.I - self.sqrt_covx @ np.linalg.pinv(zeta_ci) @ self.sqrt_covx\n",
    "\n",
    "        #     rho = (M.T.reshape(M.shape[1],M.shape[0],1) @ mubar.T) +  mubar @ M.T.reshape(M.shape[1],1,M.shape[0])\n",
    "\n",
    "        #     return np.sum(G[np.newaxis, :, :] * (self.hat_covM - rho ), axis=(1, 2))\n",
    "            \n",
    "\n",
    "        self.initialize_weights()\n",
    "        for i in range(0, self.max_iter):\n",
    "            self.update_mubar()\n",
    "            self.update_tilde_covM()\n",
    "            self.update_tilde_sigma_c()\n",
    "            self.update_zeta_c()\n",
    "            self.obj_vals[i] = self.compute_bures()\n",
    "            g = self.compute_bures_grad_c()\n",
    "            \n",
    "            \n",
    "            # print(\"g\")\n",
    "            # print(np.squeeze(g))\n",
    "            # c_i = self.c\n",
    "            \n",
    "            # print(np.squeeze(bures_grad(c_i)))\n",
    "            #  print(np.squeeze(self.compute_bures_grad_c()))\n",
    "\n",
    "            # eps = 10 * np.sqrt(np.finfo(float).eps)\n",
    "            # ga = sp.optimize.approx_fprime(c_i, bures, np.array(eps*np.ones(np.size(g))).T)\n",
    "            # ga = bures_grad_num(c_i, eps)\n",
    "            # print(\"ga\")\n",
    "            # print(ga)\n",
    "            \n",
    "            # print(sp.optimize.check_grad(bures, bures_grad, c_i))\n",
    "            \n",
    "            s = np.zeros_like(self.c)\n",
    "            idx = np.argmin(g)\n",
    "            s[idx] = 1\n",
    "            gamma = 2 / (2 + i)\n",
    "            self.c = (1 - gamma) * self.c + gamma * s\n",
    "            self.grads[i, :] = np.squeeze(g)\n",
    "            self.weights[i, :] = self.c\n",
    "\n",
    "            if self.print_iter == True:\n",
    "                print(\"iter =  \",i)\n",
    "                print(self.c)\n",
    "\n",
    "    def FW_MMD_routine(self):\n",
    "        \n",
    "        # commented part must be uncommented for gradient-checking\n",
    "        \n",
    "        def mmd(c_i):\n",
    "            return (np.linalg.norm(self.M@c_i[:,np.newaxis] - self.mux))**2\n",
    "\n",
    "        def mmd_grad(c_i):\n",
    "            return np.squeeze(2 * self.M.T @ (self.M @ c_i[:,np.newaxis] - self.mux))\n",
    "        \n",
    "        self.initialize_weights()\n",
    "        for i in range(0, self.max_iter):\n",
    "            self.update_mubar()\n",
    "            self.update_tilde_covM()\n",
    "            self.obj_vals[i] = self.compute_mmd()\n",
    "\n",
    "            g = self.compute_mmd_grad()\n",
    "\n",
    "            # print(\"g\")\n",
    "            c_i = self.c\n",
    "            # print(np.squeeze(mmd_grad(c_i)))\n",
    "            # #print(np.squeeze(self.compute_mmd_grad()))\n",
    "\n",
    "            # eps = np.sqrt(np.finfo(float).eps) * 100\n",
    "            \n",
    "            # print(\"ga\")\n",
    "            # ga = sp.optimize.approx_fprime(c_i, mmd, np.array([eps ,eps, eps]).T)\n",
    "            # print(ga)\n",
    "\n",
    "            print(sp.optimize.check_grad(mmd, mmd_grad, c_i))\n",
    "\n",
    "            s = np.zeros_like(self.c)\n",
    "            idx = np.argmin(g)\n",
    "            s[idx] = 1\n",
    "            gamma = 2 / (2 + i)\n",
    "            self.c = (1 - gamma) * self.c  + gamma * s \n",
    "            self.grads[i,:] = np.squeeze(g)\n",
    "            self.weights[i,:] = self.c\n",
    "\n",
    "            if self.print_iter == True:\n",
    "                print(\"iter = \",i)\n",
    "                print(self.c)\n",
    "\n",
    "\n",
    "def Hellinger(p, q):\n",
    "  '''\n",
    "  Function to evaluate Hellinger Distance between distributions categorical distributions p and q\n",
    "  input: distributions p and q\n",
    "  outputs: Hillnger distance between p and q\n",
    "\n",
    "  '''\n",
    "  assert np.all(p >= 0), \"first distribution must be non-negative\"\n",
    "  assert np.all(q >= 0), \"second distribution must be non-negative\"\n",
    "  assert p.size == q.size, \"input vectors must be of same size\"\n",
    "\n",
    "  p = p.reshape([p.size, 1])\n",
    "  q = q.reshape([q.size, 1])\n",
    "\n",
    "  return (1/np.sqrt(2)) * np.linalg.norm(np.sqrt(p) - np.sqrt(q))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bearing-costa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "\n",
    "M = np.array([[0, -0.5, 0.5],[1, 0, 0]])\n",
    "# M = np.array([[0, 0, 0], [0, 0, 0]])\n",
    "#M = np.ones_like(M)\n",
    "mux = np.array([[np.sqrt(3)/2], [np.sqrt(3)/2] ])\n",
    "covx = np.array([[10,6],[6,8]])\n",
    "covM = np.zeros([3,2,2])\n",
    "covM[0] = np.array([[1, 0.5],[0.5, 1]])\n",
    "covM[1] = np.array([[5, 0.6], [0.6, 7]])\n",
    "covM[2] = np.array([[4, 1], [1, 2]])\n",
    "c0 = np.ones(3)/3\n",
    " \n",
    "iterations = 10\n",
    "\n",
    "test = GM_FW(mux, M, covx, covM, c0, max_iter = iterations)\n",
    "test.reset_values()\n",
    "#test.FW_bures_routine()\n",
    "test.FW_frechet_routine()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "right-parking",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.908369880698093e-07\n",
      "1.4338831199137095e-06\n",
      "2.1190743935323343e-06\n",
      "1.2017297546573584e-06\n",
      "1.758248343906939e-06\n",
      "1.5532142638477044e-06\n",
      "1.984057302369691e-06\n",
      "9.763875361878837e-07\n",
      "1.429359211585103e-06\n",
      "1.4957066229305563e-06\n"
     ]
    }
   ],
   "source": [
    "num_ptx = 10\n",
    "dim = 100\n",
    "M = np.random.rand(dim, num_ptx)\n",
    "#M = np.zeros([dim, num_ptx])\n",
    "# M = np.ones_like(M)\n",
    "mux = np.random.rand(dim).reshape([dim, 1])\n",
    "A = np.random.rand(dim, dim)\n",
    "covx = A @ A.T\n",
    "covM = np.zeros([num_ptx, dim, dim])\n",
    "for i in range(0, num_ptx):\n",
    "    A = np.random.rand(dim, dim)\n",
    "    covM[i] = A @ A.T\n",
    "\n",
    "iterations = 10\n",
    "\n",
    "c0 = np.ones(num_ptx)/(num_ptx)\n",
    "test = GM_FW(mux, M, covx, covM, c0, max_iter=iterations)\n",
    "test.reset_values()\n",
    "test.FW_MMD_routine()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "requested-southeast",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.14545455, 0.10909091, 0.09090909, 0.07272727, 0.05454545,\n",
       "       0.18181818, 0.12727273, 0.18181818, 0.03636364, 0.        ])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "lesser-irish",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2277942513955988e-06\n",
      "2.654202485201261e-06\n",
      "2.35024122947716e-06\n",
      "2.22603766228557e-06\n",
      "2.3482181066627652e-06\n",
      "2.3032625194424033e-06\n",
      "2.2379821952121423e-06\n",
      "2.273219604305405e-06\n",
      "2.22814934868718e-06\n",
      "2.245359971973463e-06\n",
      "2.2565322210198877e-06\n",
      "2.1494028608798355e-06\n",
      "2.2425251480078697e-06\n",
      "2.2278583126094528e-06\n",
      "2.2242892452144593e-06\n",
      "2.2492752374190014e-06\n",
      "2.2166061526749827e-06\n",
      "2.234325624245001e-06\n",
      "2.2278584061832107e-06\n",
      "2.221347600570517e-06\n",
      "2.2200777402478455e-06\n",
      "2.215564219095068e-06\n",
      "2.2484332521796323e-06\n",
      "2.2027097204167375e-06\n",
      "2.2064581717903113e-06\n",
      "2.2348467570808267e-06\n",
      "2.230336004154402e-06\n",
      "2.229052435439908e-06\n",
      "2.243806536570899e-06\n",
      "2.2265105359636444e-06\n",
      "2.2338759972911976e-06\n",
      "2.2337609002480707e-06\n",
      "2.2295498818014583e-06\n",
      "2.2169410671830086e-06\n",
      "2.2252357822054494e-06\n",
      "2.2449086863542976e-06\n",
      "2.206436683080944e-06\n",
      "2.218239348339371e-06\n",
      "2.2199426564530545e-06\n",
      "2.2193198725430436e-06\n",
      "2.251637211465761e-06\n",
      "2.238393413504612e-06\n",
      "2.224641532194242e-06\n",
      "2.2559877363241316e-06\n",
      "2.2344474511663895e-06\n",
      "2.2321047400873355e-06\n",
      "2.1985922050470586e-06\n",
      "2.2251013181122043e-06\n",
      "2.235987069254336e-06\n",
      "2.242381301267617e-06\n",
      "2.2215822396355526e-06\n",
      "2.227884260385525e-06\n",
      "2.2330238269239574e-06\n",
      "2.214914102432334e-06\n",
      "2.2323587909949383e-06\n",
      "2.237213907282317e-06\n",
      "2.2135370696520267e-06\n",
      "2.2288264656123404e-06\n",
      "2.2345512449338745e-06\n",
      "2.224714613490352e-06\n",
      "2.2154834123168794e-06\n",
      "2.237437043209401e-06\n",
      "2.2337837931971165e-06\n",
      "2.223071700125217e-06\n",
      "2.238431332009698e-06\n",
      "2.2311644247857967e-06\n",
      "2.2225853111726125e-06\n",
      "2.2169507357096826e-06\n",
      "2.239841262407204e-06\n",
      "2.2237947875951597e-06\n",
      "2.2198154615298945e-06\n",
      "2.22877027552008e-06\n",
      "2.220683403151215e-06\n",
      "2.2189014687655593e-06\n",
      "2.2406002740320777e-06\n",
      "2.2266692875648527e-06\n",
      "2.233155493584116e-06\n",
      "2.2375272737402614e-06\n",
      "2.233416808415757e-06\n",
      "2.2276429265283408e-06\n",
      "2.22707785807504e-06\n",
      "2.2269716658236574e-06\n",
      "2.2289110745140847e-06\n",
      "2.2348814441974366e-06\n",
      "2.217479248346791e-06\n",
      "2.2283582502180586e-06\n",
      "2.2399864131039893e-06\n",
      "2.229261299608413e-06\n",
      "2.2279029722985356e-06\n",
      "2.229005951321052e-06\n",
      "2.220739039709373e-06\n",
      "2.219901497310672e-06\n",
      "2.2399231649730106e-06\n",
      "2.2180604608673924e-06\n",
      "2.2293719497603023e-06\n",
      "2.242523762451621e-06\n",
      "2.2227571796013255e-06\n",
      "2.2383595336722084e-06\n",
      "2.2304025326248208e-06\n",
      "2.239400080920987e-06\n",
      "0.0528178604189611\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Data Processing before PCA \n",
    "# N_samples indicates the number of samples to be drawn from data\n",
    "N_samples = 1\n",
    "Hellinger_distances = np.zeros([N_samples, 1])\n",
    "# sample_sz indicates the number of samples to be drawn from data\n",
    "sample_sz = 400\n",
    "\n",
    "\n",
    "tf.keras.datasets.mnist.load_data(path=\"mnist.npz\")\n",
    "(X_train, y), (X_test, yt) = keras.datasets.mnist.load_data()\n",
    "\n",
    "X_train = X_train / 255\n",
    "y = y / 1\n",
    "X_test = X_test / 255\n",
    "yt = yt / 1\n",
    "\n",
    "X = X_train.reshape(X_train.shape[0], X_train.shape[1] * X_train.shape[2])\n",
    "Xt = X_test.reshape(X_test.shape[0], X_test.shape[1] * X_test.shape[2])\n",
    "\n",
    "\n",
    "# PCA from scikit-learn\n",
    "\n",
    "PCA_components = 130\n",
    "pca = PCA(n_components = PCA_components)\n",
    "pca.fit(X)\n",
    "# np.sum(pca.explained_variance_ratio_)\n",
    "P = pca.components_\n",
    "X_hat = X@P.T\n",
    "Xt_hat = Xt@P.T\n",
    "\n",
    "# Creation and Testing and Training samples\n",
    "\n",
    "n_classes = np.size(np.unique(y))\n",
    "means_i = np.zeros([n_classes, PCA_components])\n",
    "covs_i = np.zeros([n_classes, PCA_components, PCA_components])\n",
    "\n",
    "Training_Data = {}\n",
    "Training_Lables = {}\n",
    "for i in range(0, 10):\n",
    "  Training_Data[str(i)] = X_hat[y == i]\n",
    "  Training_Lables[str(i)] = y[y == i]\n",
    "  means_i[i] = np.mean(Training_Data[str(i)], axis = 0)\n",
    "  covs_i[i] = np.cov(Training_Data[str(i)].T)\n",
    "\n",
    "\n",
    "Testing_Data = {}\n",
    "Testing_Lables = {}\n",
    "for i in range(0, 10):\n",
    "  Testing_Data[str(i)] = Xt_hat[yt == i]\n",
    "  Testing_Lables[str(i)] = yt[yt == i]\n",
    "  \n",
    "# Slicing thorugh test set\n",
    "\n",
    "Hellinger_metric = np.zeros(N_samples)\n",
    "\n",
    "for sample_iter in range(0, N_samples): \n",
    "  sz = np.random.randint(10, 2000, [10])\n",
    "  s = np.random.dirichlet(sz, 1).T\n",
    "  ints = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "  p = s\n",
    "  counts_sample = np.floor(sample_sz * p)\n",
    "  sample = np.empty([0, PCA_components], dtype = float)\n",
    "  sample_labels = np.empty(0, dtype = float)\n",
    "  counter = 0\n",
    "  for k in ints:\n",
    "    idx = np.random.choice(np.arange(0, Testing_Data[str(k)].shape[0]), size = np.int(counts_sample[counter]), replace = False )\n",
    "    sample = np.append(sample, Testing_Data[str(k)][idx], axis = 0)\n",
    "    sample_labels = np.append(sample_labels, Testing_Lables[str(k)][idx], axis = 0)\n",
    "    counter = counter + 1\n",
    "\n",
    "  mean_x = np.mean(sample, axis = 0)\n",
    "  covx = np.cov(sample.T)\n",
    "\n",
    "  mux = mean_x[np.newaxis,:].T\n",
    "  M = means_i.T\n",
    "  covM = covs_i\n",
    "  \n",
    "\n",
    "\n",
    "  # Frank_Wolfe is invoked\n",
    "  c0 = np.ones(n_classes)/n_classes\n",
    "  iterations = 100\n",
    "  \n",
    "  \n",
    "  MNIST = GM_FW(mux, M, covx, covM, c0, max_iter = iterations, print_iter = False)\n",
    "  \n",
    "  MNIST.FW_MMD_routine()\n",
    "  Hellinger_metric[sample_iter] = Hellinger(MNIST.c, s)\n",
    "  print(Hellinger_metric[sample_iter])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fifteen-actress",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.16772277, 0.02910891, 0.17544554, 0.11742574, 0.12653465,\n",
       "       0.11207921, 0.06673267, 0.05920792, 0.        , 0.14574257])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MNIST.c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "equal-wallet",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.14657956],\n",
       "       [0.0202841 ],\n",
       "       [0.17381758],\n",
       "       [0.12953466],\n",
       "       [0.12931951],\n",
       "       [0.11252194],\n",
       "       [0.09168747],\n",
       "       [0.04448029],\n",
       "       [0.00187804],\n",
       "       [0.14989685]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "grand-channel",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Hellinger(p,q):\n",
    "  '''\n",
    "  Function to evaluate Hellinger Distance between distributions categorical distributions p and q\n",
    "  input: distributions p and q\n",
    "  outputs: Hillnger distance between p and q\n",
    "\n",
    "  '''\n",
    "  assert np.all(p >= 0), \"first distribution must be non-negative\" \n",
    "  assert np.all(q >= 0), \"second distribution must be non-negative\"\n",
    "  assert p.size == q.size, \"input vectors must be of same size\"\n",
    "\n",
    "  p = p.reshape([p.size, 1]) \n",
    "  q = q.reshape([q.size, 1]) \n",
    "\n",
    "  return (1/np.sqrt(2)) * np.linalg.norm( np.sqrt(p) - np.sqrt(q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "threatened-convention",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9481152573588495"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 - Hellinger(MNIST.c, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "decreased-visibility",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0210801 ],\n",
       "       [0.166506  ],\n",
       "       [0.06654268],\n",
       "       [0.06074725],\n",
       "       [0.12808842],\n",
       "       [0.10591242],\n",
       "       [0.08285953],\n",
       "       [0.08196471],\n",
       "       [0.16542776],\n",
       "       [0.12087113]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "frequent-vermont",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01797203, 0.1681998 , 0.0655025 , 0.05763437, 0.13961039,\n",
       "       0.091998  , 0.09507493, 0.06078322, 0.15694106, 0.14628372])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MNIST.c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "copyrighted-cabinet",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01130345, 0.56102229, 0.07662679, 0.0279048 , 0.0183663 ,\n",
       "       0.01852785, 0.01588996, 0.01739065, 0.01058555, 0.00706925,\n",
       "       0.00643785, 0.00685781, 0.00556978, 0.00546221, 0.00457756,\n",
       "       0.00547457, 0.00430023, 0.00428731, 0.00340144, 0.00578065,\n",
       "       0.008231  , 0.00732366, 0.00694462, 0.00776018, 0.00646413,\n",
       "       0.00545903, 0.00555747, 0.00621676, 0.00550672, 0.00534905,\n",
       "       0.00452354, 0.00396553, 0.00377714, 0.00310301, 0.00293698,\n",
       "       0.00286797, 0.00344374, 0.00275388, 0.00289212, 0.00299938,\n",
       "       0.00229725, 0.00234716, 0.00197026, 0.0018147 , 0.00192196,\n",
       "       0.00212481, 0.00209173, 0.00178811, 0.00156238, 0.00257819,\n",
       "       0.00193827, 0.00151559, 0.00147174, 0.00138873, 0.00248851,\n",
       "       0.0040003 , 0.00389536, 0.00356178, 0.00401818, 0.00361892,\n",
       "       0.0033748 , 0.00336329, 0.00315605, 0.00286371, 0.0027559 ,\n",
       "       0.00291554, 0.00257194, 0.00271428, 0.00255357, 0.00225775,\n",
       "       0.00242274, 0.00221548, 0.00193186, 0.00195018, 0.00166361,\n",
       "       0.00151486, 0.00163686, 0.00182958, 0.00192283, 0.00185914,\n",
       "       0.00149099, 0.00148364, 0.00143303, 0.00122417, 0.00157481,\n",
       "       0.00134638, 0.00111109, 0.00099534, 0.00118233, 0.00088928,\n",
       "       0.00137813, 0.00133645, 0.00137843, 0.00138262, 0.00111506,\n",
       "       0.00211005, 0.00168957, 0.00161836, 0.00257005, 0.00250536,\n",
       "       0.00236795, 0.00230935, 0.00237094, 0.00230615, 0.00208824,\n",
       "       0.00204314, 0.00190592, 0.00186856, 0.00194642, 0.00184733,\n",
       "       0.00190883, 0.00179836, 0.00166844, 0.00180633, 0.00160665,\n",
       "       0.00149085, 0.00149425, 0.00137788, 0.0017126 , 0.00149774,\n",
       "       0.00153414, 0.00142095, 0.00124927, 0.00119256, 0.00105024,\n",
       "       0.00145561, 0.00136658, 0.00133603, 0.0010758 , 0.00098499,\n",
       "       0.001553  , 0.00142367, 0.00124847, 0.00107722, 0.0010439 ,\n",
       "       0.00101252, 0.00164272, 0.00137473, 0.00125962, 0.00115022,\n",
       "       0.00104963, 0.00103613, 0.00087415, 0.00136688, 0.00133963,\n",
       "       0.00118184, 0.0010723 , 0.00098601, 0.00166079, 0.00185764,\n",
       "       0.00176304, 0.00167653, 0.00159047, 0.00168725, 0.00176271,\n",
       "       0.00163555, 0.00155501, 0.00146076, 0.001375  , 0.00131442,\n",
       "       0.00144328, 0.00146059, 0.00133132, 0.00136149, 0.00127467,\n",
       "       0.00118171, 0.00140176, 0.00129424, 0.00113607, 0.00106803,\n",
       "       0.00099782, 0.00105375, 0.00102952, 0.00129093, 0.00126005,\n",
       "       0.00108363, 0.00096021, 0.00085061, 0.00121482, 0.00117302,\n",
       "       0.00113245, 0.00106424, 0.00096855, 0.00091045, 0.00131808,\n",
       "       0.00123663, 0.0010344 , 0.00103628, 0.00084742, 0.00089581,\n",
       "       0.00078953, 0.00122163, 0.00115283, 0.00113028, 0.00098536,\n",
       "       0.00089056, 0.00082602, 0.00129345, 0.00151346, 0.00145531,\n",
       "       0.00139118, 0.00153864, 0.00145347, 0.00133259, 0.00136406,\n",
       "       0.00132671, 0.00135092, 0.00149248, 0.00137601, 0.00129174,\n",
       "       0.00120862, 0.00111209, 0.0013674 , 0.00133745, 0.00132939,\n",
       "       0.00125123, 0.00122754, 0.00113343, 0.0010344 , 0.00125057,\n",
       "       0.00123433, 0.00113271, 0.00110617, 0.00095847, 0.00090522,\n",
       "       0.00123515, 0.00112871, 0.00110556, 0.00102616, 0.00097748,\n",
       "       0.00092322, 0.00128354, 0.00110188, 0.0010724 , 0.00100268,\n",
       "       0.00092883, 0.00088413, 0.00088132, 0.00120906, 0.0012045 ,\n",
       "       0.00102417, 0.00094548, 0.00093679, 0.00133169, 0.00128708,\n",
       "       0.00124901, 0.00112511, 0.00104784, 0.00089574, 0.00082782,\n",
       "       0.0011924 , 0.00131001, 0.00125677, 0.0012019 , 0.00115881,\n",
       "       0.00130993, 0.00132176, 0.0012846 , 0.00121942, 0.00121059,\n",
       "       0.00114775, 0.00133208, 0.00120413, 0.00113982, 0.00102283,\n",
       "       0.0009914 , 0.00092731, 0.00113931, 0.00114415, 0.00114092,\n",
       "       0.00107519, 0.00102475, 0.00094811, 0.0011929 , 0.0011774 ,\n",
       "       0.00104077, 0.00100517, 0.00087648, 0.00115087, 0.00107513,\n",
       "       0.00099961, 0.0009722 , 0.00094729, 0.00088758, 0.0011846 ,\n",
       "       0.00111779, 0.00114313, 0.00105956, 0.00106004, 0.00101898,\n",
       "       0.00094832, 0.00124994, 0.00121376, 0.00104677, 0.00092875,\n",
       "       0.00091023, 0.00122977, 0.00119613, 0.00113441, 0.00103187,\n",
       "       0.0009983 , 0.00101508, 0.00102215, 0.00133233, 0.00125353,\n",
       "       0.00119173, 0.00114475, 0.00106476, 0.00120743, 0.00118227,\n",
       "       0.00111801, 0.00112481, 0.001119  , 0.0010558 , 0.00122306,\n",
       "       0.00112483, 0.00108902, 0.00103623, 0.00102074, 0.00124745,\n",
       "       0.00121324, 0.00114471, 0.00107644, 0.00106649, 0.00105617,\n",
       "       0.00093445, 0.00114853, 0.00109918, 0.00099488, 0.00097733,\n",
       "       0.00092213, 0.00088805, 0.00111198, 0.00105768, 0.00104413,\n",
       "       0.00104873, 0.00098807, 0.00098397, 0.00085788, 0.00110172,\n",
       "       0.00107416, 0.00104151, 0.00097404, 0.00091497, 0.00116867,\n",
       "       0.00115974, 0.00104908, 0.00100875, 0.00096146, 0.00099567,\n",
       "       0.00126656, 0.00116751, 0.00116951, 0.00113235, 0.00099884,\n",
       "       0.00096928, 0.00091332, 0.00117647, 0.0011178 , 0.00108919,\n",
       "       0.00104276, 0.00120353, 0.00115694, 0.00107789, 0.00105364,\n",
       "       0.00099922, 0.00117217, 0.00115565, 0.00110083, 0.00110058,\n",
       "       0.00109291, 0.00097837, 0.00096359, 0.00115889, 0.00110531,\n",
       "       0.00105501, 0.001011  , 0.00100298, 0.00120913, 0.00117222,\n",
       "       0.00111941, 0.00111551, 0.00101477, 0.00091373, 0.00091909,\n",
       "       0.00086561, 0.00105944, 0.001006  , 0.00099307, 0.00097276,\n",
       "       0.00093913, 0.00116472, 0.00111681, 0.00111479, 0.00105334,\n",
       "       0.00102712, 0.00092166, 0.00115004, 0.00104405, 0.00102239,\n",
       "       0.00102142, 0.00097529, 0.00096689, 0.00120222, 0.00118101,\n",
       "       0.00109881, 0.00104788, 0.00102323, 0.0009966 , 0.00123188,\n",
       "       0.00123541, 0.00112851, 0.00108503, 0.00101134, 0.00096826,\n",
       "       0.00110816, 0.00109664, 0.00101999, 0.0010181 , 0.0009742 ,\n",
       "       0.00092579, 0.00107982, 0.00104509, 0.00103934, 0.0010282 ,\n",
       "       0.00098283, 0.00116689, 0.00111845, 0.0010845 , 0.00098719,\n",
       "       0.00098113, 0.00096892, 0.00092461, 0.00110113, 0.00110081,\n",
       "       0.00101404, 0.00100477, 0.00096272, 0.00091259, 0.00109799,\n",
       "       0.00106404, 0.00105101, 0.00102482, 0.00092309, 0.00111837,\n",
       "       0.00107622, 0.0010691 , 0.00102068, 0.00102622, 0.00097796,\n",
       "       0.00095926, 0.00115687, 0.00113083, 0.0011336 , 0.00103719,\n",
       "       0.00100002, 0.00094506, 0.00114439, 0.00111618, 0.00101536,\n",
       "       0.00101474, 0.00098814, 0.0011937 , 0.00116924, 0.00112913,\n",
       "       0.00104711, 0.00103711, 0.00102722, 0.00117199, 0.00112834,\n",
       "       0.00109172, 0.00101894, 0.00098298, 0.00113532, 0.00112535,\n",
       "       0.00103621, 0.0009948 , 0.00099249, 0.00095683, 0.00111947,\n",
       "       0.00108056, 0.00107573, 0.00103163, 0.00102257, 0.00101353,\n",
       "       0.0009913 , 0.00115789, 0.00106374, 0.00102387, 0.00101716,\n",
       "       0.00094174, 0.00090218, 0.00086867, 0.0010305 , 0.00099223,\n",
       "       0.00098667, 0.00097415, 0.00098127, 0.00115986, 0.00110754,\n",
       "       0.00108503, 0.00104178, 0.00095536, 0.00095429, 0.00093334,\n",
       "       0.00110647, 0.00108473, 0.00100373, 0.00097001, 0.00096708,\n",
       "       0.00115255, 0.00109425, 0.00107056, 0.00103372, 0.00104949,\n",
       "       0.00102691, 0.00121158, 0.00121393, 0.00111717, 0.00108226,\n",
       "       0.00099024, 0.00096032, 0.00108897, 0.00105948, 0.00102951,\n",
       "       0.00096205, 0.00095018, 0.00108651, 0.00104849, 0.00105263,\n",
       "       0.0010458 , 0.0010388 , 0.00100264, 0.00096597, 0.00110728,\n",
       "       0.00108338, 0.00099679, 0.00096061, 0.00095506, 0.00094621,\n",
       "       0.00109551, 0.00107211, 0.00100218, 0.00096354, 0.00093621,\n",
       "       0.00108941, 0.00105422, 0.00104942, 0.00105951, 0.00097357,\n",
       "       0.00095692, 0.0011165 , 0.00108256, 0.00107792, 0.0010295 ,\n",
       "       0.00100819, 0.00093588, 0.00109804, 0.0010656 , 0.00104336,\n",
       "       0.00104497, 0.00102807, 0.0009485 , 0.00111349, 0.00112419,\n",
       "       0.00106504, 0.00102931, 0.00102883, 0.00100877, 0.00099275,\n",
       "       0.00115721, 0.00112456, 0.00107516, 0.0010572 , 0.00098642,\n",
       "       0.00115262, 0.00115218, 0.00103214, 0.00100074, 0.0009945 ,\n",
       "       0.00112582, 0.00111899, 0.00103967, 0.00100587, 0.00098307,\n",
       "       0.00097634, 0.00094654, 0.00107406, 0.00104863, 0.00101509,\n",
       "       0.00101026, 0.00094781, 0.00108907, 0.00106737, 0.00099243,\n",
       "       0.00098461, 0.00097748, 0.00094869, 0.00091274, 0.00090538,\n",
       "       0.00104256, 0.00102412, 0.00099088, 0.0009814 , 0.00097841,\n",
       "       0.00112571, 0.00108139, 0.00106322, 0.0010302 , 0.0009543 ,\n",
       "       0.00110441, 0.00110341, 0.00103362, 0.00103992, 0.00102348,\n",
       "       0.00099508, 0.00099292, 0.00114491, 0.00109238, 0.00107442,\n",
       "       0.00104383, 0.00103089, 0.00095686, 0.00110964, 0.0010873 ,\n",
       "       0.00108771, 0.00106019, 0.00101469, 0.00102175, 0.00117415,\n",
       "       0.00110478, 0.00108926, 0.00097361, 0.00096528, 0.00108439,\n",
       "       0.00105289, 0.00103335, 0.00102909, 0.00096309, 0.00095616,\n",
       "       0.00108035, 0.00104492, 0.00101389, 0.00099001, 0.0009966 ,\n",
       "       0.00096493, 0.00109694, 0.00103429, 0.00102839, 0.00098902,\n",
       "       0.0009812 , 0.00096071, 0.00109049, 0.00106104, 0.00105746,\n",
       "       0.00098667, 0.00096897, 0.00095785, 0.0010915 , 0.00105409,\n",
       "       0.00102516, 0.00102607, 0.00102489, 0.00096297, 0.00109872,\n",
       "       0.00108281, 0.00105404, 0.00105492, 0.00104142, 0.00097036,\n",
       "       0.00110844, 0.00106368, 0.00104409, 0.00101574, 0.00101631,\n",
       "       0.00100246, 0.00114106, 0.00114971, 0.00112211, 0.00107682,\n",
       "       0.00106255, 0.00100171, 0.00114072, 0.00114018, 0.00107028,\n",
       "       0.00105648, 0.00102923, 0.00092433, 0.00103211, 0.00102544,\n",
       "       0.00099844, 0.00097979, 0.00095144, 0.00106739, 0.00105827,\n",
       "       0.00105673, 0.00102844, 0.00102475, 0.00096996, 0.00109086,\n",
       "       0.00107388, 0.00100662, 0.00097335, 0.00095367, 0.00092524,\n",
       "       0.00091877, 0.00103661, 0.00103102, 0.00100565, 0.00101126,\n",
       "       0.00101165, 0.00100066, 0.0011253 , 0.00108417, 0.00106965,\n",
       "       0.00100163, 0.00097398, 0.00110126, 0.0010858 , 0.00102665,\n",
       "       0.00102504, 0.00101352, 0.00097768, 0.00110222, 0.00108505,\n",
       "       0.00105833, 0.00105845, 0.00106941, 0.0010423 , 0.000976  ,\n",
       "       0.00110524, 0.00108768, 0.00108772, 0.00104733, 0.0010345 ,\n",
       "       0.00097668, 0.00110351, 0.00107865, 0.00106521, 0.00106875,\n",
       "       0.0009631 , 0.00106718, 0.00104167, 0.00104447, 0.00101372,\n",
       "       0.00098741, 0.00098413, 0.0010946 , 0.00103206, 0.00102178,\n",
       "       0.00100301, 0.00095458, 0.00093729, 0.00104761, 0.0010452 ,\n",
       "       0.00101984, 0.00098549, 0.00098019, 0.00098172, 0.0010938 ,\n",
       "       0.00109215, 0.00106561, 0.00100222, 0.00098796, 0.00097856,\n",
       "       0.00109352, 0.00105778, 0.0010418 , 0.00101576, 0.00101548,\n",
       "       0.0009628 , 0.00107918, 0.00106544, 0.00104182, 0.00100643,\n",
       "       0.00101217, 0.0009511 , 0.00106843, 0.00105352, 0.00105073,\n",
       "       0.00102623, 0.00101358, 0.00113548, 0.00113725, 0.00112105,\n",
       "       0.00108368, 0.00105933, 0.00104681, 0.00099483, 0.00111399,\n",
       "       0.0011141 , 0.001052  , 0.00105999, 0.00103629, 0.00099883,\n",
       "       0.00111855, 0.00110602, 0.00108832, 0.00108999, 0.00106637,\n",
       "       0.00096218, 0.00106028, 0.00104365, 0.00102032, 0.00101802,\n",
       "       0.00096201, 0.00106699, 0.00101883, 0.00100137, 0.00097174,\n",
       "       0.00097165, 0.0009471 , 0.00105403, 0.00105161, 0.00103974,\n",
       "       0.0010269 , 0.00100376, 0.00097322, 0.00108092, 0.00107987,\n",
       "       0.00102831, 0.00101462, 0.00095749, 0.00094881, 0.00105616,\n",
       "       0.00106015, 0.00103685, 0.00103533, 0.00100083, 0.0009776 ,\n",
       "       0.00096487, 0.00107527, 0.00106253, 0.00106232, 0.00100538,\n",
       "       0.00099385, 0.00110589, 0.00108318, 0.00107005, 0.00103587,\n",
       "       0.00104031, 0.00104157, 0.00099085, 0.00110084, 0.00107897,\n",
       "       0.00106761, 0.00107003, 0.00104885, 0.00101179, 0.00112404,\n",
       "       0.00111405, 0.00105596, 0.00103955, 0.00102936, 0.00114274,\n",
       "       0.00102573, 0.0010038 , 0.00099993, 0.00100391, 0.00095813,\n",
       "       0.00105516, 0.00102469, 0.00102161, 0.00099813, 0.00098531,\n",
       "       0.00108662, 0.00107719, 0.00102182, 0.00100777, 0.00098597,\n",
       "       0.00098487, 0.00108818, 0.00105656, 0.00104697, 0.00104948,\n",
       "       0.00102676, 0.00102622, 0.0009796 , 0.00108129, 0.00106966,\n",
       "       0.00101496, 0.00099432, 0.00096283, 0.00094881, 0.00105141,\n",
       "       0.00104023, 0.00103841, 0.00101774, 0.00100641, 0.00111248,\n",
       "       0.00108041, 0.00108581, 0.00103685, 0.00103688, 0.00101525,\n",
       "       0.00112181, 0.00110965, 0.00105478, 0.00105333, 0.00104283,\n",
       "       0.00102268, 0.00098984, 0.00109454, 0.00108329, 0.00106977,\n",
       "       0.00107142, 0.00105134, 0.00106004, 0.00116631, 0.00105089,\n",
       "       0.00100077, 0.00098767, 0.0009665 , 0.00105926, 0.00105735,\n",
       "       0.0010122 , 0.0009834 , 0.00096949, 0.00094878, 0.00104297,\n",
       "       0.00104138, 0.00103249, 0.00103748, 0.00100924, 0.00098767,\n",
       "       0.0010827 , 0.00107098, 0.00101844, 0.00100885, 0.00100685,\n",
       "       0.00096461, 0.00105946, 0.0010468 , 0.00102696, 0.00102607,\n",
       "       0.00099567, 0.00109347, 0.001082  , 0.00106129, 0.00105161,\n",
       "       0.00105707, 0.00100441, 0.00100472, 0.00110322, 0.00108303,\n",
       "       0.00105084, 0.00104011, 0.0009946 , 0.00099521, 0.00109432,\n",
       "       0.00108205, 0.00106326, 0.00105294, 0.00102223, 0.00112172,\n",
       "       0.00112763, 0.00107576, 0.00107678, 0.00105606, 0.00104251,\n",
       "       0.00103356, 0.00113337, 0.0011145 , 0.00111627, 0.00100961,\n",
       "       0.00097113, 0.00105798, 0.00104478, 0.00101763, 0.00101546,\n",
       "       0.00099548, 0.00099857, 0.00108844, 0.00103867, 0.00102992,\n",
       "       0.00101796, 0.00099852, 0.0009974 , 0.0009706 , 0.00105918,\n",
       "       0.0010483 , 0.00100483, 0.00098585, 0.00098501, 0.00107741,\n",
       "       0.00106856, 0.00102077, 0.00100842, 0.00098144, 0.00098423,\n",
       "       0.00096405, 0.00105508, 0.00105477, 0.00104392, 0.00102536,\n",
       "       0.00101551, 0.00110933, 0.00107921, 0.00107976, 0.00103634])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(MNIST.grads, axis = 1)/2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "capital-minister",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "95a4f5fbaeda06bbae9fa19d04e185298ed03d2c19902c3494da40431ca5f25a"
  },
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('tf': conda)",
   "language": "python",
   "name": "python37464bittfconda97144d421cc44a0f9290de43f2658a01"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
